{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random \n",
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "session = requests.session()\n",
    "headers = {'User-Agent': ua.random}\n",
    "from string import punctuation\n",
    "punctuation = punctuation + '—–“”«»'\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "from sklearn.metrics import accuracy_score\n",
    "stopWords = set(stopwords.words('russian'))\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page(url, headers):\n",
    "    posts_list = []\n",
    "    response = session.get(url, headers=headers)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    posts = soup.find_all('span', {'class': '_reachbanner_'})\n",
    "    for post in posts:\n",
    "        i = post.get_text()\n",
    "        posts_list.append(i)\n",
    "    return posts_list[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(posts):\n",
    "    clean_rew = []\n",
    "    for_train = []\n",
    "    for_test = []\n",
    "    for r in posts:\n",
    "        r = r.replace('\\n', '')\n",
    "        r = r.replace('\\r', '')\n",
    "        r = r.lower()\n",
    "        small_list = []\n",
    "        for p in punctuation:\n",
    "            if p in r:\n",
    "                r = r.replace(p, ' ')\n",
    "        w = nltk.word_tokenize(r)\n",
    "        for elem in w:\n",
    "            ana = morph.parse(elem) \n",
    "            n = ana[0].normal_form\n",
    "            if n not in stopWords:\n",
    "                small_list.append(n)\n",
    "        clean_rew.append(small_list)\n",
    "    for s in clean_rew[:30]:\n",
    "        for c in s:\n",
    "            for_train.append(c)\n",
    "    for s in clean_rew[30:40]:\n",
    "        for_test.append(s)\n",
    "    return for_train, for_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(first_list, sec_list):\n",
    "    unique_list = []\n",
    "    clean_unique_list = []\n",
    "    for i in first_list:\n",
    "        if i not in sec_list:\n",
    "            unique_list.append(i)\n",
    "    for c in Counter(unique_list).items():\n",
    "        if c[1]>2:\n",
    "            clean_unique_list.append(c[0])\n",
    "    return clean_unique_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_type_detect(words_list, bad_words, good_words):\n",
    "    word_scores = {'negative':0, 'positive':0}\n",
    "    for i in words_list:\n",
    "        if i in bad_words:\n",
    "            word_scores['negative'] += 1\n",
    "        elif i in good_words:\n",
    "            word_scores['positive'] += 1\n",
    "    return Counter(word_scores).most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tests, first_uniques, second_uniques):\n",
    "    gold = []\n",
    "    result = []\n",
    "    for t in tests.items():\n",
    "        gold.append(t[1])\n",
    "        n = simple_type_detect(t[0], first_uniques, second_uniques) \n",
    "        result.append(n[0][0])\n",
    "    return accuracy_score(result, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bad = 'https://www.kinopoisk.ru/film/462682/reviews/ord/rating/status/bad/perpage/100/'\n",
    "url_good = 'https://www.kinopoisk.ru/film/462682/reviews/ord/rating/status/good/perpage/200/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = clean(page(url_bad, headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = clean(page(url_good, headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rews = {}\n",
    "for b in bad[1]:\n",
    "    test_rews[tuple(b)] = 'negative'\n",
    "for g in good[1]:\n",
    "    test_rews[tuple(g)] = 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_uniques = unique(bad[0], good[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_uniques = unique(good[0], bad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_rews, bad_uniques, good_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#среди плохих тестовых рецензий правильно определяется только 6/10\n",
    "#среди хороших тестовых рецензий правильно определяется 10/10\n",
    "#видимо так проиходит потому что больше уникальных слов у хороших рецензий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как улучшить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Можно воспользоваться нейросетью и обучить ее на большем количестве текстов (плохих и хороших; пусть еще смотрит не слова, а словосочетания; определяет синонимы), брать не только один фильм, и вообще брать разные типы текстов\n",
    "2. Можно получше убрать шум (слова с опечатками, имена героев если они остаются и тд)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
